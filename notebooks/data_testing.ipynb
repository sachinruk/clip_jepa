{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db325596",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from src import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = config.HyperParameters()\n",
    "\n",
    "dataset: datasets.Dataset = datasets.load_dataset(\n",
    "    hyper_parameters.data_config.dataset, split=\"train\"\n",
    ")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ac050",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6446fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6cbf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fadba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def collate_fn(batch: list[dict[str, Image.Image | str]]) -> dict[str, list[list[dict[str, Any]]]]:\n",
    "    images = [\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": data_instance[\"image\"],\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        for data_instance in batch\n",
    "    ]\n",
    "    texts = [\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": data_instance[\"caption\"]}],\n",
    "            }\n",
    "        ]\n",
    "        for data_instance in batch\n",
    "    ]\n",
    "    return {\n",
    "        \"images\": images,\n",
    "        \"texts\": texts,\n",
    "    }\n",
    "\n",
    "\n",
    "dl = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f753112",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "isinstance(dataset, datasets.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e042a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148d3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e87642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import data, config, model\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d3ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = config.HyperParameters()\n",
    "train_dl, valid_dl = data.get_dataset(hyper_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7468a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d8b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_components = model.init_model(hyper_parameters.llm_model_config, device=torch.device(\"mps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bff471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "isinstance(model_components.model, nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97eff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b16e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    text_embeddings = model.embed_text(batch[\"texts\"], model_components)\n",
    "    # image_embeddings = model.embed_image(batch[\"images\"], model_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    text_embeddings.shape,\n",
    "    # image_embeddings.shape,\n",
    "    (text_embeddings**2).sum(),\n",
    "    # (image_embeddings**2).sum(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc5bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = model.get_lora_model(model_components.model, hyper_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280301d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_components.model = lora_model\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_embeddings = model.embed_text(batch[\"texts\"], model_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a5ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    text_embeddings.shape,\n",
    "    # image_embeddings.shape,\n",
    "    (text_embeddings**2).sum(),\n",
    "    # (image_embeddings**2).sum(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "389fa998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c5dcfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
